## Kafka의 기본개념과 대용량 서비스에서 비동기 프로세스의 중요성 이해

### Kafka

- 이벤트 스트리밍 플랫폼

### Kafka 실행

1. 주키퍼 실행

   - 주키퍼는 2181포트를 기본적으로 사용

   `$(카프카 디렉터리)/bin/zookeeper-server-start.sh config/zookeeper.properties`

2. [server.properties](http://server.properties) 변경
   - `advertised.listeners=PLAINTEXT://localhost:9092`
3. kafka server 실행
   - `$(카프카 디렉터리)/bin/kafka-server-start.sh config/server.propertie`
4. kafka topic 생성
   - `$(카프카 디렉터리)/bin/kafka-topics.sh --create --topic topic-example1 --bootstrap-server localhost:9092`
   - 카프카 토픽 정보 보기 : `$(카프카 디렉터리)/bin/kafka-topics.sh --describe --topic topic-example1 --bootstrap-server localhost:9092`
5. kafka producer
   - `$(카프카 디렉터리)/bin/kafka-console-producer.sh --topic topic-example1 --bootstrap-server localhost:9092`
6. kafka consumer
   - `$(카프카 디렉터리)/bin/kafka-console-consumer.sh --topic topic-example1 --bootstrap-server [localhost:9092](http://localhost:9092)`
   - —from-beginning 옵션 : 처음부터 보기

## Kafka 브로커, 토픽 등 서버구성 상세설명

[sever.properties](http://sever.properties) → log.dir → 저장되는 실제 위치 확인

### 토픽이름 제약사항

- 249자 미만으로 생성.
- 영어대소문자, 0~9숫자, 마침표, 언더바, 하이픈 조합으로 생성가능 … 등

### 파티션

- 파티션은 실제로 데이터가 저장되는 곳
- 파티션은 리더파티션과 팔로워 파티션이 존재
- 리더파티션은 읽기/쓰기가 모두 일어남
- 팔로워 파티션은 읽기/쓰기가 일어나지 않고 지속적으로 데이터를 싱크

## Kafka 파티션에 대해 이해하기

- 컨슈머 그룹은 current offset을 통해 각각의 파티션에서 읽어가는 레코드를 관리
- `$(카프카 디렉터리)/bin/kafka-console-consumer.sh --topic topic-example1 --bootstrap-server [localhost:9092](http://localhost:9092) --group group명`
- `$(카프카 디렉터리)/bin/kafka-consumer-groups.sh --topic topic-example1 --bootstrap-server [localhost:9092](http://localhost:9092) --group team-a --describe`
- 파티션을 여러개 두면 라운드로빈 방식으로 레코드 저장
- 하나의 파티션을 사용하면 레코드 순서를 보장, 여러개의 파티션을 사용하면 레코드 순서를 보장x

### Kafka Cluster 구성하기

1. [server.properties](http://server.properties) 수정
   - [broker.id](http://broker.id) 수정
   - listeners 주석 해제후 [localhost](http://localhost):9092로 수정
   - advertised.listeners 주석
   - log.dir 수정
2. [server1.properties](http://server1.properties) 수정
   - [broker.id](http://broker.id) 수정 → 1
   - listeners 주석 해제후 [localhost](http://localhost):9092로 수정 → localhost:9093
   - advertised.listeners 주석
   - log.dir 수정
3. [server2.properties](http://server1.properties) 수정
   - [broker.id](http://broker.id) 수정 → 2
   - listeners 주석 해제후 [localhost](http://localhost):9092로 수정 → localhost:9094
   - advertised.listeners 주석
   - log.dir 수정
4. sever1 실행
   - $(카프카 디렉터리)/bin/kafka-server-start.sh config/server.properties&
   - & 백그라운드로 실행
5. server2 실행
6. server3 실행
7. topic 생성
   - `$(카프카 홈)/bin/kafka-topics.sh --create --topic topic2 --bootstrap-server [localhost:9093](http://localhost:9093) --partitions 3 --replication-factor 2`
   - 아무 브로커나 요청가능
   - `--partition 3` : 파티션 3개 생성
   - `--replication-factor` : 3개의 파티션중 복사본 2개 생성
   - `bin/kafka-topics.sh —describe —topic topic2 —bootstrap-server [localhost:9093](http://localhost:9093)`
8. Producer 실행
   - `bin/kafka-console-producer.sh --topic topic2 --bootstrap-server localhost:9092, localhost:9093, localhost:9094 --from-beginning`
9. consumer 실행
   - `bin/kafka-console-consumer.sh --topic topic2 --bootstrap-server localhost:9092, localhost:9093, localhost:9094 --from-beginning`

## Kafka Cli의 다양한 기능 이해

### topics

- `--partitions 파티션 갯수`
- `--alter —topic 토픽명 —partitions 갯수 —bootstrap-server (host)` : 토픽 변경
- `kafka-configs.sh  --alter -- entity-type topics --entity-name topic3 --add-config retention.ms=86400000` : 카프카 레코드 삭제시간 설정

### producer

- `--request-required-acks 1`
- `--message-send-max-retries 50` : 재전송 최대 횟수 설정
- `kafka-verifiable-producer.sh topic3 --max-message3`

### Conusmer

- `--from-beginning` : 처음부터 오프셋을 설정
- `--from-beginning --group group1` : 그룹 지정

### consumer-groups

- `kafka-consumer-groups.sh --list` : 컨슈머 그룹 보기
- `kafka-consumer-groups.sh --describe --group ()`

### Sinc

1. `config/connect-standalone.properties` 변경
   - key.converter.schemas.enable=false
   - value.converter.schemas.enable=false
2. File Sink connect 설정파일 - config/connect-file-sink.properties
   - topics=topic3
3. 단일모드 connect 실행
   - bin/connect-standalone.sh config/connect-standalone.properties
   - config/connect-file-sink.properties

## AWS Managed Kafka Service
